{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b98a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deepiforest.algorithms.dif import DIF\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../deep-i-forest/deep-iforest\"))\n",
    "from algorithms.dif import DIF\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f6486cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>momento</th>\n",
       "      <th>1-0005</th>\n",
       "      <th>5-0005</th>\n",
       "      <th>1-_006</th>\n",
       "      <th>5-_006</th>\n",
       "      <th>1-_007</th>\n",
       "      <th>5-_007</th>\n",
       "      <th>1-_008</th>\n",
       "      <th>5-_008</th>\n",
       "      <th>1-_010</th>\n",
       "      <th>...</th>\n",
       "      <th>1-_098</th>\n",
       "      <th>5-_098</th>\n",
       "      <th>1-_099</th>\n",
       "      <th>5-_099</th>\n",
       "      <th>1-0112</th>\n",
       "      <th>5-0112</th>\n",
       "      <th>1-0116</th>\n",
       "      <th>5-0116</th>\n",
       "      <th>1-0109</th>\n",
       "      <th>5-0109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-588.88</td>\n",
       "      <td>-580.21</td>\n",
       "      <td>-590.50</td>\n",
       "      <td>-582.25</td>\n",
       "      <td>-593.51</td>\n",
       "      <td>-585.46</td>\n",
       "      <td>-595.51</td>\n",
       "      <td>-587.47</td>\n",
       "      <td>-575.36</td>\n",
       "      <td>...</td>\n",
       "      <td>-588.17</td>\n",
       "      <td>-581.42</td>\n",
       "      <td>-594.26</td>\n",
       "      <td>-586.26</td>\n",
       "      <td>-589.46</td>\n",
       "      <td>-581.75</td>\n",
       "      <td>-592.92</td>\n",
       "      <td>-586.26</td>\n",
       "      <td>-593.93</td>\n",
       "      <td>-586.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-588.38</td>\n",
       "      <td>-579.71</td>\n",
       "      <td>-590.80</td>\n",
       "      <td>-582.46</td>\n",
       "      <td>-593.80</td>\n",
       "      <td>-585.67</td>\n",
       "      <td>-595.55</td>\n",
       "      <td>-587.59</td>\n",
       "      <td>-574.11</td>\n",
       "      <td>...</td>\n",
       "      <td>-588.34</td>\n",
       "      <td>-581.63</td>\n",
       "      <td>-594.51</td>\n",
       "      <td>-586.26</td>\n",
       "      <td>-589.29</td>\n",
       "      <td>-581.58</td>\n",
       "      <td>-592.80</td>\n",
       "      <td>-586.26</td>\n",
       "      <td>-594.13</td>\n",
       "      <td>-586.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-584.41</td>\n",
       "      <td>-575.74</td>\n",
       "      <td>-585.83</td>\n",
       "      <td>-577.66</td>\n",
       "      <td>-591.38</td>\n",
       "      <td>-583.21</td>\n",
       "      <td>-589.84</td>\n",
       "      <td>-578.04</td>\n",
       "      <td>-563.34</td>\n",
       "      <td>...</td>\n",
       "      <td>-588.17</td>\n",
       "      <td>-581.33</td>\n",
       "      <td>-592.88</td>\n",
       "      <td>-584.34</td>\n",
       "      <td>-588.50</td>\n",
       "      <td>-580.62</td>\n",
       "      <td>-590.21</td>\n",
       "      <td>-583.75</td>\n",
       "      <td>-593.68</td>\n",
       "      <td>-585.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-573.73</td>\n",
       "      <td>-565.27</td>\n",
       "      <td>-570.31</td>\n",
       "      <td>-562.81</td>\n",
       "      <td>-578.91</td>\n",
       "      <td>-571.24</td>\n",
       "      <td>-578.61</td>\n",
       "      <td>-565.90</td>\n",
       "      <td>-555.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-584.79</td>\n",
       "      <td>-576.87</td>\n",
       "      <td>-580.62</td>\n",
       "      <td>-568.15</td>\n",
       "      <td>-586.96</td>\n",
       "      <td>-578.75</td>\n",
       "      <td>-578.66</td>\n",
       "      <td>-571.19</td>\n",
       "      <td>-590.88</td>\n",
       "      <td>-582.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-567.27</td>\n",
       "      <td>-558.55</td>\n",
       "      <td>-562.26</td>\n",
       "      <td>-554.55</td>\n",
       "      <td>-570.69</td>\n",
       "      <td>-562.93</td>\n",
       "      <td>-567.18</td>\n",
       "      <td>-557.51</td>\n",
       "      <td>-545.99</td>\n",
       "      <td>...</td>\n",
       "      <td>-579.11</td>\n",
       "      <td>-570.99</td>\n",
       "      <td>-572.11</td>\n",
       "      <td>-560.43</td>\n",
       "      <td>-583.45</td>\n",
       "      <td>-574.91</td>\n",
       "      <td>-571.06</td>\n",
       "      <td>-563.56</td>\n",
       "      <td>-587.38</td>\n",
       "      <td>-578.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>637</td>\n",
       "      <td>-237.18</td>\n",
       "      <td>-253.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>638</td>\n",
       "      <td>-237.10</td>\n",
       "      <td>-253.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>639</td>\n",
       "      <td>-237.14</td>\n",
       "      <td>-253.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>640</td>\n",
       "      <td>-237.10</td>\n",
       "      <td>-253.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>641</td>\n",
       "      <td>-237.10</td>\n",
       "      <td>-253.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>641 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     momento  1-0005  5-0005  1-_006  5-_006  1-_007  5-_007  1-_008  5-_008  \\\n",
       "0          1 -588.88 -580.21 -590.50 -582.25 -593.51 -585.46 -595.51 -587.47   \n",
       "1          2 -588.38 -579.71 -590.80 -582.46 -593.80 -585.67 -595.55 -587.59   \n",
       "2          3 -584.41 -575.74 -585.83 -577.66 -591.38 -583.21 -589.84 -578.04   \n",
       "3          4 -573.73 -565.27 -570.31 -562.81 -578.91 -571.24 -578.61 -565.90   \n",
       "4          5 -567.27 -558.55 -562.26 -554.55 -570.69 -562.93 -567.18 -557.51   \n",
       "..       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "636      637 -237.18 -253.66     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "637      638 -237.10 -253.70     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "638      639 -237.14 -253.74     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "639      640 -237.10 -253.70     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "640      641 -237.10 -253.74     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "     1-_010  ...  1-_098  5-_098  1-_099  5-_099  1-0112  5-0112  1-0116  \\\n",
       "0   -575.36  ... -588.17 -581.42 -594.26 -586.26 -589.46 -581.75 -592.92   \n",
       "1   -574.11  ... -588.34 -581.63 -594.51 -586.26 -589.29 -581.58 -592.80   \n",
       "2   -563.34  ... -588.17 -581.33 -592.88 -584.34 -588.50 -580.62 -590.21   \n",
       "3   -555.00  ... -584.79 -576.87 -580.62 -568.15 -586.96 -578.75 -578.66   \n",
       "4   -545.99  ... -579.11 -570.99 -572.11 -560.43 -583.45 -574.91 -571.06   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "636     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "637     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "638     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "639     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "640     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "     5-0116  1-0109  5-0109  \n",
       "0   -586.26 -593.93 -586.30  \n",
       "1   -586.26 -594.13 -586.51  \n",
       "2   -583.75 -593.68 -585.84  \n",
       "3   -571.19 -590.88 -582.63  \n",
       "4   -563.56 -587.38 -578.71  \n",
       "..      ...     ...     ...  \n",
       "636     NaN     NaN     NaN  \n",
       "637     NaN     NaN     NaN  \n",
       "638     NaN     NaN     NaN  \n",
       "639     NaN     NaN     NaN  \n",
       "640     NaN     NaN     NaN  \n",
       "\n",
       "[641 rows x 77 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('vacuum_sensor_data.csv', sep = ';')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4a489e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column to have consistent naming \n",
    "import re\n",
    "\n",
    "def clean_column(col):\n",
    "    if col == 'momento':\n",
    "        return col\n",
    "    match = re.match(r\"(\\d)-_?(\\d+)\", col)\n",
    "    if match:\n",
    "        sensor, comp = match.groups()\n",
    "        return f\"{sensor}-{int(comp):04d}\"\n",
    "    return col  # fallback in case format is already correct\n",
    "\n",
    "# Apply renaming\n",
    "data.columns = [clean_column(col) for col in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "daeb3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows(seconds) where data from any sensor is missing\n",
    "data=data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b335815d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 77)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40bbbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split columns into train and validation\n",
    "defective_columns = ['1-0116', '5-0116', '1-0109', '5-0109']\n",
    "normal_control_columns = ['1-0008', '5-0008', '1-0064', '5-0064']\n",
    "validation_columns = defective_columns + normal_control_columns\n",
    "\n",
    "df_validation = data[['momento'] + validation_columns]\n",
    "train_columns = [col for col in data.columns if col not in validation_columns]\n",
    "df_train = data[train_columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b32ee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network additional parameters: {'n_hidden': [500, 100], 'n_emb': 20, 'skip_connection': None, 'dropout': None, 'activation': 'tanh', 'be_size': 100}\n",
      "training done, time: 1.3\n",
      "Best result:\n",
      "Window: (1, 533)\n",
      "Threshold percentile: 90\n",
      "Confusion Matrix:\n",
      " [[3 1]\n",
      " [4 0]]\n",
      "Classification Report:\n",
      "              precision  recall  f1-score  support\n",
      "0              0.428571   0.750  0.545455    4.000\n",
      "1              0.000000   0.000  0.000000    4.000\n",
      "accuracy       0.375000   0.375  0.375000    0.375\n",
      "macro avg      0.214286   0.375  0.272727    8.000\n",
      "weighted avg   0.214286   0.375  0.272727    8.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from itertools import product\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. Prepare training data ---\n",
    "\n",
    "# Drop 'momento', transpose so each row = one component signal over time\n",
    "X_train_raw = df_train.drop(columns=['momento']).T  # shape: (num_components, n_timesteps)\n",
    "\n",
    "# Scale each component (row) independently\n",
    "def scale_rows(X):\n",
    "    return np.array([StandardScaler().fit_transform(row.reshape(-1, 1)).flatten() for row in X])\n",
    "\n",
    "X_train_scaled = scale_rows(X_train_raw.values)\n",
    "n_timesteps_train = X_train_scaled.shape[1]\n",
    "\n",
    "# --- 3. Train DIF model ---\n",
    "dif = DIF(\n",
    "    n_ensemble=100,\n",
    "    n_hidden=[500, 100],\n",
    "    n_emb=20,\n",
    "    activation='tanh',\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    verbose=1\n",
    ")\n",
    "dif.fit(X_train_scaled)\n",
    "\n",
    "# --- 4. Prepare labels for validation components ---\n",
    "label_map = {col: 1 if col in defective_columns else 0 for col in validation_columns}\n",
    "y_val = np.array([label_map[col] for col in validation_columns])\n",
    "\n",
    "# --- 5. Grid search over time windows and thresholds ---\n",
    "# We use only windows matching train timesteps count exactly.\n",
    "\n",
    "momento_values = np.sort(data['momento'].unique())\n",
    "window_size = n_timesteps_train\n",
    "\n",
    "# Generate candidate windows of length window_size in the momento timeline\n",
    "window_starts = momento_values[:-window_size + 1]\n",
    "window_ends = window_starts + window_size - 1\n",
    "\n",
    "window_ranges = list(zip(window_starts, window_ends))\n",
    "\n",
    "threshold_percentiles = [90, 92, 94, 95, 96, 98]\n",
    "\n",
    "results = []\n",
    "\n",
    "for (start, end), perc in product(window_ranges, threshold_percentiles):\n",
    "    # Select validation window\n",
    "    mask = (df_validation['momento'] >= start) & (df_validation['momento'] <= end)\n",
    "    df_val_window = df_validation.loc[mask, ['momento'] + validation_columns]\n",
    "\n",
    "    if df_val_window.shape[0] != window_size:\n",
    "        # Skip windows that don't match exact length (sanity check)\n",
    "        print(f\"Skipping window {start}-{end} due to length mismatch: val {df_val_window.shape[0]} vs train {window_size}\")\n",
    "        continue\n",
    "\n",
    "    # Prepare validation features\n",
    "    X_val_raw = df_val_window.drop(columns=['momento']).T.values  # shape: (num_components, window_size)\n",
    "\n",
    "    # Scale validation data **using training scalers independently for each component**\n",
    "    # Note: scaling each row of validation with its own scaler fitted on that row is wrong here,\n",
    "    # so instead we standard scale using the same means/stds as training per component.\n",
    "\n",
    "    # For each component, fit scaler on training row, then transform validation row:\n",
    "    X_val_scaled = np.empty_like(X_val_raw)\n",
    "    for i in range(X_val_raw.shape[0]):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train_raw.values[i].reshape(-1, 1))\n",
    "        X_val_scaled[i] = scaler.transform(X_val_raw[i].reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Compute anomaly scores\n",
    "    scores = dif.decision_function(X_val_scaled)\n",
    "\n",
    "    # Threshold and predict anomalies\n",
    "    threshold = np.percentile(scores, perc)\n",
    "    preds = (scores >= threshold).astype(int)\n",
    "\n",
    "    # Evaluate\n",
    "    cm = confusion_matrix(y_val, preds)\n",
    "    cr = classification_report(y_val, preds, zero_division=0, output_dict=True)\n",
    "\n",
    "    results.append({\n",
    "        'window': (start, end),\n",
    "        'threshold_percentile': perc,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': cr,\n",
    "        'accuracy': cr['accuracy'],\n",
    "        'precision_defective': cr['1']['precision'],\n",
    "        'recall_defective': cr['1']['recall'],\n",
    "        'f1_defective': cr['1']['f1-score'],\n",
    "    })\n",
    "\n",
    "# --- 6. Select best result by F1 score for defective class ---\n",
    "if len(results) == 0:\n",
    "    print(\"No valid results found (all windows skipped or no predictions).\")\n",
    "else:\n",
    "    best_result = max(results, key=lambda r: r['f1_defective'])\n",
    "    print(\"Best result:\")\n",
    "    print(f\"Window: {best_result['window']}\")\n",
    "    print(f\"Threshold percentile: {best_result['threshold_percentile']}\")\n",
    "    print(\"Confusion Matrix:\\n\", best_result['confusion_matrix'])\n",
    "    print(\"Classification Report:\")\n",
    "    print(pd.DataFrame(best_result['classification_report']).transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e9d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepiforest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
